{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiements with NER on MS MARCO Document dataset\n",
    "\n",
    "This notebook is a sandbox for using ðŸ¤— Transformers for NER in the indexing pipeline and at search time for MS MARCO Document ranking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, AutoTokenizer, AutoModelForTokenClassification\n",
    "\n",
    "# model_name = 'dbmdz/bert-base-cased-finetuned-conll03-english'\n",
    "model_name = 'mrm8488/mobilebert-finetuned-ner'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, model_max_length=512)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_name)\n",
    "ner = pipeline('ner', tokenizer=tokenizer, model=model, ignore_subwords=True, grouped_entities=True, ignore_labels=\"O\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 91.1 ms, sys: 10 ms, total: 101 ms\n",
      "Wall time: 101 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'MISC',\n",
       "  'score': 0.7413530349731445,\n",
       "  'word': '##rch',\n",
       "  'start': 34,\n",
       "  'end': 37},\n",
       " {'entity_group': 'ORG',\n",
       "  'score': 0.9833260774612427,\n",
       "  'word': 'us bank',\n",
       "  'start': 42,\n",
       "  'end': 49},\n",
       " {'entity_group': 'PER',\n",
       "  'score': 0.9997989535331726,\n",
       "  'word': 'john smith',\n",
       "  'start': 121,\n",
       "  'end': 131},\n",
       " {'entity_group': 'ORG',\n",
       "  'score': 0.9999570250511169,\n",
       "  'word': 'accenture',\n",
       "  'start': 156,\n",
       "  'end': 165},\n",
       " {'entity_group': 'PER',\n",
       "  'score': 0.999747097492218,\n",
       "  'word': 'max mustermann',\n",
       "  'start': 183,\n",
       "  'end': 197},\n",
       " {'entity_group': 'ORG',\n",
       "  'score': 0.9998007118701935,\n",
       "  'word': 'us bank',\n",
       "  'start': 201,\n",
       "  'end': 208}]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "ner(\"In the context of using Elasticsearch for US Bank, we see similarities with other observability use-cases. We spoke with John Smith and his collegaues from Accenture who confirmed to Max Mustermann at US Bank that their use-case would fit.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 58.3 ms, sys: 5.76 ms, total: 64 ms\n",
      "Wall time: 64.1 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'ORG',\n",
       "  'score': 0.9763613343238831,\n",
       "  'word': 'elasticsearch',\n",
       "  'start': 0,\n",
       "  'end': 13},\n",
       " {'entity_group': 'ORG',\n",
       "  'score': 0.9148470163345337,\n",
       "  'word': 'kibana',\n",
       "  'start': 18,\n",
       "  'end': 24},\n",
       " {'entity_group': 'ORG',\n",
       "  'score': 0.9994836449623108,\n",
       "  'word': 'elastic',\n",
       "  'start': 43,\n",
       "  'end': 50},\n",
       " {'entity_group': 'LOC',\n",
       "  'score': 0.9981455206871033,\n",
       "  'word': 'amsterdam',\n",
       "  'start': 69,\n",
       "  'end': 78}]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "ner(\"Elasticsearch and Kibana are products from Elastic which is based in Amsterdam.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 74 ms, sys: 3.55 ms, total: 77.5 ms\n",
      "Wall time: 78.9 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'MISC',\n",
       "  'score': 0.7912053167819977,\n",
       "  'word': 'manhattan project',\n",
       "  'start': 31,\n",
       "  'end': 48},\n",
       " {'entity_group': 'LOC',\n",
       "  'score': 0.9998374581336975,\n",
       "  'word': 'new york',\n",
       "  'start': 72,\n",
       "  'end': 80},\n",
       " {'entity_group': 'MISC',\n",
       "  'score': 0.967934250831604,\n",
       "  'word': 'wikipedia',\n",
       "  'start': 133,\n",
       "  'end': 142}]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "ner(\"What were the key parts of the Manhattan Project? Does it take place in New York or is that just something that people read about on Wikipedia?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.models import SequenceTagger as FlairSequenceTagger\n",
    "from flair.data import Sentence as FlairSentence\n",
    "from syntok import segmenter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-08 16:12:24,965 loading file /Users/josh/.flair/models/en-ner-fast-conll03-v0.4.pt\n"
     ]
    }
   ],
   "source": [
    "tagger = FlairSequenceTagger.load('ner-fast')\n",
    "\n",
    "def flair_extract(text):\n",
    "    paragraphs = segmenter.process(text)\n",
    "\n",
    "    words = set()\n",
    "    for sentences in paragraphs:\n",
    "        for tokens in sentences:\n",
    "            flair_sentence = FlairSentence([token.value for token in tokens], use_tokenizer=False)\n",
    "            tagger.predict(flair_sentence)\n",
    "            for entity in flair_sentence.get_spans('ner'):\n",
    "                words.add(entity.text)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 401 ms, sys: 20.4 ms, total: 422 ms\n",
      "Wall time: 433 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Accenture', 'Elasticsearch', 'John Smith', 'Max Mustermann', 'US Bank'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "flair_extract(\"In the context of using Elasticsearch for US Bank, we see similarities with other observability use-cases. We spoke with John Smith and his collegaues from Accenture who confirmed to Max Mustermann at US Bank that their use-case would fit.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 152 ms, sys: 3.43 ms, total: 155 ms\n",
      "Wall time: 157 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Amsterdam', 'Elastic', 'Elasticsearch', 'Kibana'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "flair_extract(\"Elasticsearch and Kibana are products from Elastic which is based in Amsterdam.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
